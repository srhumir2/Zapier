---
title: "Applying for the data science position"
author: "Reza"
date: "April 07, 2016"
output: pdf_document
---
\usepackage[colorlinks]{hyperref}

Dear 

I am writing to express my interest in working with Zapier as data scientist. I am doing the last steps of doctorate in Mathematics in FSU Jena Germany. I have plenty of experience in research and teaching. Along with  pure math, I cooperated with experts in other fields including economists and urban planners.

To name some, With urban planners we developed an algorithm for assessing accessibility in cities using big graphs and I programmed it in MatLab. I also am familiar with, by nature statistical, techniques of remote sensing, and help then running them through R programming. Together with economists, we studied financial derivatives with aim of understanding their nature and their relationship with gambling.

Now after several years of mainly doing academic jobs, I would like to enter to a more practical yet active sector and found the data analysis really interesting and perfectly fitted to my theoretical background. In the university and other training, I did several courses in Statistics, Statistical inference, Operational Research, Philosophy of science,   Machine learning, Programming and Data structures as well as data banks and SQL. I am already advanced in R programming and familiar with python with interest in learning them more deeply. Some works of mine are available in my [\underline{github page}}](https://github.com/srhumir). 

In terms of transferable skills, I learned how to translate real world problems into mathematical statements and vice versa through math work and cooperations. I am good in analyzing and problem solving as key skills in mathematics. I did cooperated with teams of different scientific and social backgrounds. Also for several years I thought mathematics to students of various scientific and social backgrounds through which you have to be enormously patient, friendly and understanding as well as being able to express complicated problems in understandable manners. Last but not least, I am a good independent fast leaner and great in finding the way the jobs are done using online resources.


In R I love the "dplyr"" and "data.table" packages for their fast and efficient capability of cleaning and summarizing the data. "raster" is a very nice package for working with grid ?data?. For plotting one should not underestimate the base plotting system of R but whenever there is too much coding needed using it, I prefer to use "ggplot2". Rmarkdown in combination with LaTex is a great tool for making reports. "caret" is a great package gatehring machine learning techniques and whatever preprocessing needed in one place.


Because of my thesis work, I can not yet work full time.  Plus working with the interesting, creative and creditable Zapier is a huge oportunity to earn invaluable experiemce and credit for my career prospect. So I would like to propose a two-month unpaid remote trainee program. I would do the jobs you expect from a data analyst. I am sure I can rapidly learn whatever needed for the job and I haven't learned yet.

Enclosed please find my resume and a sample report of a work of mine. I am looking forward to hearing from you and ready to start from April.


With highest regards

Reza Hosseini

###Explanation of a work
MODIS is a satellite which provides mainly two kind of products. First, land surface temperature (LST) and second Normalized Difference Vegetation Index (NDVI), an index between -1 and 1  of which higher values indicate more dense vegetation. This data are provided in weekly intervals. The problem is that it is really coerce, with resolution of 960m. On the other hand we had an image of the SPOT satellite of 1.5m resolution which unfortunately does not provide LST information but fortunately provides enough data for computing NDVI. On the other hand, it is known that NDVI and LST have an inverse relationship. We use this fact to compute LST in the resolution of SPOT.

Briefly, I computed two linear models. One to convert NDVI of SPOT to NDVI of MODIS and another to convert NDVI to LST. The first one is quite straightforward. But the second model had to be based on not all pixels but just the so called hot edge pixels. i.e. pixels which are among the hottest 5 percent when NDVI is binned in 0.3 unit intervals. Scatter plot below shows NDVI vs LST. Red dots are hot edges and green squares indicate the fitted linear model. 

 ```{r cache = T, echo = F, message = F}
 #compute the degree two polynimial on hot edge of LST 
#converting NDVI to LST. We also draw plot to check
#if the hot edge pixels and ploynomial are acceptable
polynomail <- function(NDVIMODIS, LSTMODIS){
       ### Get hot edge pixels
       ####Bin NDVI from 0.1 to 1 by 0.05 intervals
       NDVIMODIS <- crop(NDVIMODIS, LSTMODIS)
       LSTMODIS <- crop(LSTMODIS, NDVIMODIS)
       index <- complete.cases(getValues(NDVIMODIS),getValues(LSTMODIS))
       HotEdgepixels <- data.table(NDVI = getValues(NDVIMODIS)[index], LST = getValues(LSTMODIS)[index])
       NDVILST <- HotEdgepixels
       HotEdgepixels[,bin:= floor((NDVI+1)/.03)]
       qua <- with(HotEdgepixels,tapply(LST, bin, function(x)  quantile(x,probs = 0.9,na.rm = T)))
       a <- numeric()
       for (i in 1:length(HotEdgepixels$NDVI)){
              a[i] <- (HotEdgepixels$LST[i] >= qua[[as.character(HotEdgepixels$bin[i])]]) *
                     HotEdgepixels$NDVI[i]
       }
       HotEdgepixels[, hotedge :=  a ]
       HotEdgepixels[, hotedge:= as.logical(hotedge)]
       
       HotEdgepixels <- subset(HotEdgepixels, hotedge & NDVI > .2)
       #draw plot for comparison
       plot(NDVILST$NDVI, NDVILST$LST, xlab = "NDVI", ylab = "LST")
       points(HotEdgepixels$NDVI, HotEdgepixels$LST, pch = 16, col = "red")
       ####Fit polynomial to hot edge
       x <- HotEdgepixels$NDVI
       y <- HotEdgepixels$LST
       #pol <- lm(y ~ x + I(x^2))
       pol <- lm(y ~ x)
       #draw a plot to check
       v <- seq(-1,1, by = 0.05)
       w <- pol$coefficients[1] + pol$coefficients[2] * v #+
       #       pol$coefficients[3]* v^2 
       points(v,w, pch = 15, col = "green")
       pol
}
##1. Input data
#x <- matrix(rnorm(400), 20)
#y<- matrix(rnorm(400), 20)

library(raster)
library(data.table)
#print("chosse NDVI of MODIS of resolution equal to LST")
NDVIMODIS <- raster(file.choose())
#print("choose LST of MODIS")
LSTMODIS <- raster(file.choose())

pol <- polynomail(NDVIMODIS, LSTMODIS)

 ```

To refine the results, I used the fact that the temperature of a point is dependent to its surrounding points. To take into account this fact, I computed the residuals of the model above with respect to all pixels. Then trained a neural network with NDVI values of each pixel and its eight surrounding pixels as input and the pixels residual as output.

The 

